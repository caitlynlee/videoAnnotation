{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tkinter as Tk\n",
    "from PIL import Image, ImageTk, ImageDraw, ImageFont\n",
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import csv\n",
    "from random import randint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify clip number \n",
    "clipNum = 'CLIP_011'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Saves new frames with ovals overlayed on original frames \n",
    "### to show saved coordinate locations of multiple individuals/groups\n",
    "### \n",
    "\n",
    "def saveVideo_MULT(sourceDir, destDir, positionsFile, verbose=True, start=1):\n",
    "    df = pd.read_csv(positionsFile, header=None)\n",
    "    df.dropna(inplace=True)\n",
    "    colors = [(randint(0,255), randint(0,255), randint(0,255)) for x in df.index]\n",
    "    font = ImageFont.truetype(\"VCR_OSD_MONO_1.001.ttf\", 16)\n",
    "    #font = ImageFont.load_default()\n",
    "    for col in df.columns[start:]:\n",
    "        if start == 0:\n",
    "            imageNum = col + 1\n",
    "        else: \n",
    "            imageNum = col\n",
    "        \n",
    "        if verbose: \n",
    "            if col % 10 == 0: print (col)\n",
    "        path = os.path.join(sourceDir, 'frame_%04d.png' % (imageNum))\n",
    "        newPath = os.path.join(destDir, 'frame_%04d.png' % (imageNum))\n",
    "\n",
    "        img = Image.open(path, 'r')\n",
    "        img = img.resize((1200,700))\n",
    "        img_w, img_h = img.size\n",
    "        background = Image.new('RGBA', (img_w, img_h), (255, 255, 255, 255))\n",
    "        background.paste(img, (0,0))\n",
    "        draw = ImageDraw.Draw(background)\n",
    "        draw.text((20,20), str(col), (255,0,0), font=font)\n",
    "        for ID, person in enumerate(df[col]):\n",
    "            coords = [float(x) for x in person[1:-1].split(',')]\n",
    "            draw.ellipse(coords, outline=colors[ID], width=2)\n",
    "            \n",
    "            # OPTIONAL: draw text on image with ID number for each individual/group\n",
    "            draw.text((coords[0], coords[1]), str(ID), colors[ID], font=font)         \n",
    "        background.save(newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Saves new frames with ovals toverlayed on original frames \n",
    "### Only shows locations for individuals tracked mulitple times\n",
    "### Expects ID numbers for \"good\" trackings and \"bad\" trackings to verify which \n",
    "### duplicate trackings should be kept/thrown out\n",
    "###\n",
    "\n",
    "def saveVideo_DUPLICATES(sourceDir, destDir, positionsFile, goodSet, badSet, verbose=True):\n",
    "    df = pd.read_csv(positionsFile, header=None)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    # Using different colors to distinguish \"good\"/\"bad\" trackings\n",
    "    red = (244, 80, 65)\n",
    "    green = (47, 196, 39)\n",
    "    #font = ImageFont.load_default()\n",
    "    font = ImageFont.truetype(\"VCR_OSD_MONO_1.001.ttf\", 15)\n",
    "    for col in df.columns[1:]: \n",
    "        \n",
    "        if verbose: \n",
    "            if col % 10 == 0: print (col)\n",
    "        path = os.path.join(sourceDir, 'frame_%04d.png' % (col))\n",
    "        newPath = os.path.join(destDir, 'frame_%04d.png' % (col))\n",
    "\n",
    "        img = Image.open(path, 'r')\n",
    "        img = img.resize((1200,700))\n",
    "        img_w, img_h = img.size\n",
    "        background = Image.new('RGBA', (img_w, img_h), (255, 255, 255, 255))\n",
    "        background.paste(img, (0,0))\n",
    "        draw = ImageDraw.Draw(background)\n",
    "        draw.text((20,20), str(col), (255,0,0), font=font)\n",
    "        for ID in goodSet:\n",
    "            person = df[col][ID]\n",
    "            coords = [float(x) for x in person[1:-1].split(',')]\n",
    "            draw.ellipse(coords, outline=green, width=2)\n",
    "            draw.text((coords[0], coords[1]), str(ID), green, font=font)\n",
    "            \n",
    "        for ID in badSet: \n",
    "            person = df[col][ID]\n",
    "            coords = [float(x) for x in person[1:-1].split(',')]\n",
    "            draw.ellipse(coords, outline=red, width=2)\n",
    "            draw.text((coords[0], coords[1]), str(ID), red, font=font)\n",
    "        \n",
    "        background.save(newPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tracked frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saveVideo_MULT('data/' + clipNum + '/FRAMES', \n",
    "               'data/' + clipNum + '/TRACKED_FRAMES', \n",
    "               'data/' + clipNum + '/DATA/positions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**command to generate video**  \n",
    "\n",
    "`ffmpeg -framerate 10 -i data/CLIP_011/TRACKED_FRAMES/frame_%04d.png -b 5000k data/CLIP_011/VIDEO/ALL.mp4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicate frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data/' + clipNum + '/DUPLICATES'):\n",
    "    os.mkdir('data/' + clipNum + '/DUPLICATES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveVideo_DUPLICATES('data/' + clipNum + '/FRAMES', \n",
    "                     'data/' + clipNum + '/DUPLICATES', \n",
    "                     'data/' + clipNum + '/DATA/positions.csv',\n",
    "                     [26,50,64],\n",
    "                     [25,49,62])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**command to generate video**  \n",
    "\n",
    "`ffmpeg -framerate 10 -i data/CLIP_011/DUPLICATES/frame_%04d.png -b 5000k data/CLIP_011/VIDEO/DUPLICATES.mp4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data/' + clipNum + '/CLUSTERED_FRAMES'):\n",
    "    os.mkdir('data/' + clipNum + '/CLUSTERED_FRAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saveVideo_MULT('data/' + clipNum + '/FRAMES', \n",
    "               'data/' + clipNum + '/CLUSTERED_FRAMES', \n",
    "               'data/' + clipNum + '/DATA/clusters_positions.csv',\n",
    "                start=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**command to generate video**  \n",
    "\n",
    "`ffmpeg -framerate 10 -i data/CLIP_011/CLUSTERED_FRAMES/frame_%04d.png -b 5000k data/CLIP_011/VIDEO/CLUSTERS.mp4`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
